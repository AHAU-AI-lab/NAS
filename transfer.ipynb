{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f90618-81d4-4cac-9748-e89ce01be816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43b01b-3f4f-4eae-92b3-5890bcd05737",
   "metadata": {},
   "source": [
    "# Train the source domain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dea9777-3a9b-46be-9c43-2865b565b524",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               58624     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,556\n",
      "Trainable params: 67,523\n",
      "Non-trainable params: 1,033\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9756    0.9877    0.9816        81\n",
      "           2     0.9897    0.9796    0.9846        98\n",
      "\n",
      "   micro avg     0.9838    0.9838    0.9838       247\n",
      "   macro avg     0.9835    0.9842    0.9838       247\n",
      "weighted avg     0.9839    0.9838    0.9838       247\n",
      " samples avg     0.9838    0.9838    0.9838       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 0 80  1]\n",
      " [ 1  1 96]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9286    0.9108    0.9196       157\n",
      "           1     0.8860    0.9048    0.8953       189\n",
      "           2     0.9609    0.9567    0.9588       231\n",
      "\n",
      "   micro avg     0.9272    0.9272    0.9272       577\n",
      "   macro avg     0.9252    0.9241    0.9246       577\n",
      "weighted avg     0.9276    0.9272    0.9273       577\n",
      " samples avg     0.9272    0.9272    0.9272       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[143  13   1]\n",
      " [ 10 171   8]\n",
      " [  1   9 221]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               117248    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,292\n",
      "Trainable params: 119,811\n",
      "Non-trainable params: 1,481\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        68\n",
      "           1     0.9877    0.9877    0.9877        81\n",
      "           2     0.9898    0.9898    0.9898        98\n",
      "\n",
      "   micro avg     0.9919    0.9919    0.9919       247\n",
      "   macro avg     0.9925    0.9925    0.9925       247\n",
      "weighted avg     0.9919    0.9919    0.9919       247\n",
      " samples avg     0.9919    0.9919    0.9919       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 0 80  1]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9304    0.9363    0.9333       157\n",
      "           1     0.9086    0.8942    0.9013       189\n",
      "           2     0.9571    0.9654    0.9612       231\n",
      "\n",
      "   micro avg     0.9341    0.9341    0.9341       577\n",
      "   macro avg     0.9320    0.9320    0.9320       577\n",
      "weighted avg     0.9339    0.9341    0.9340       577\n",
      " samples avg     0.9341    0.9341    0.9341       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[147   9   1]\n",
      " [ 11 169   9]\n",
      " [  0   8 223]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                3664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               2176      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,260\n",
      "Trainable params: 6,515\n",
      "Non-trainable params: 745\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9710    0.9853    0.9781        68\n",
      "           1     0.9620    0.9383    0.9500        81\n",
      "           2     0.9697    0.9796    0.9746        98\n",
      "\n",
      "   micro avg     0.9676    0.9676    0.9676       247\n",
      "   macro avg     0.9676    0.9677    0.9676       247\n",
      "weighted avg     0.9675    0.9676    0.9675       247\n",
      " samples avg     0.9676    0.9676    0.9676       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 2 76  3]\n",
      " [ 0  2 96]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8938    0.9108    0.9022       157\n",
      "           1     0.8730    0.8730    0.8730       189\n",
      "           2     0.9474    0.9351    0.9412       231\n",
      "\n",
      "   micro avg     0.9081    0.9081    0.9081       577\n",
      "   macro avg     0.9047    0.9063    0.9055       577\n",
      "weighted avg     0.9084    0.9081    0.9082       577\n",
      " samples avg     0.9081    0.9081    0.9081       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[143  13   1]\n",
      " [ 13 165  11]\n",
      " [  4  11 216]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,196\n",
      "Trainable params: 8,611\n",
      "Non-trainable params: 585\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9706    0.9851        68\n",
      "           1     0.9630    0.9630    0.9630        81\n",
      "           2     0.9700    0.9898    0.9798        98\n",
      "\n",
      "   micro avg     0.9757    0.9757    0.9757       247\n",
      "   macro avg     0.9777    0.9744    0.9759       247\n",
      "weighted avg     0.9760    0.9757    0.9757       247\n",
      " samples avg     0.9757    0.9757    0.9757       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[66  2  0]\n",
      " [ 0 78  3]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9730    0.9172    0.9443       157\n",
      "           1     0.8872    0.9153    0.9010       189\n",
      "           2     0.9402    0.9524    0.9462       231\n",
      "\n",
      "   micro avg     0.9307    0.9307    0.9307       577\n",
      "   macro avg     0.9334    0.9283    0.9305       577\n",
      "weighted avg     0.9317    0.9307    0.9309       577\n",
      " samples avg     0.9307    0.9307    0.9307       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[144  12   1]\n",
      " [  3 173  13]\n",
      " [  1  10 220]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               16896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,396\n",
      "Trainable params: 26,851\n",
      "Non-trainable params: 1,545\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9697    0.9412    0.9552        68\n",
      "           1     0.9500    0.9383    0.9441        81\n",
      "           2     0.9604    0.9898    0.9749        98\n",
      "\n",
      "   micro avg     0.9595    0.9595    0.9595       247\n",
      "   macro avg     0.9600    0.9564    0.9581       247\n",
      "weighted avg     0.9595    0.9595    0.9594       247\n",
      " samples avg     0.9595    0.9595    0.9595       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[64  3  1]\n",
      " [ 2 76  3]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9133    0.8726    0.8925       157\n",
      "           1     0.8534    0.8624    0.8579       189\n",
      "           2     0.9322    0.9524    0.9422       231\n",
      "\n",
      "   micro avg     0.9012    0.9012    0.9012       577\n",
      "   macro avg     0.8996    0.8958    0.8975       577\n",
      "weighted avg     0.9013    0.9012    0.9011       577\n",
      " samples avg     0.9012    0.9012    0.9012       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[137  19   1]\n",
      " [ 11 163  15]\n",
      " [  2   9 220]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,156\n",
      "Trainable params: 17,123\n",
      "Non-trainable params: 1,033\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        68\n",
      "           1     1.0000    0.9877    0.9938        81\n",
      "           2     0.9899    1.0000    0.9949        98\n",
      "\n",
      "   micro avg     0.9960    0.9960    0.9960       247\n",
      "   macro avg     0.9966    0.9959    0.9962       247\n",
      "weighted avg     0.9960    0.9960    0.9959       247\n",
      " samples avg     0.9960    0.9960    0.9960       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 0 80  1]\n",
      " [ 0  0 98]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9198    0.9490    0.9342       157\n",
      "           1     0.9167    0.8730    0.8943       189\n",
      "           2     0.9447    0.9610    0.9528       231\n",
      "\n",
      "   micro avg     0.9289    0.9289    0.9289       577\n",
      "   macro avg     0.9270    0.9277    0.9271       577\n",
      "weighted avg     0.9287    0.9289    0.9286       577\n",
      " samples avg     0.9289    0.9289    0.9289       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[149   7   1]\n",
      " [ 12 165  12]\n",
      " [  1   8 222]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                3664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,956\n",
      "Trainable params: 4,403\n",
      "Non-trainable params: 553\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9851    0.9706    0.9778        68\n",
      "           1     0.9176    0.9630    0.9398        81\n",
      "           2     0.9789    0.9490    0.9637        98\n",
      "\n",
      "   micro avg     0.9595    0.9595    0.9595       247\n",
      "   macro avg     0.9606    0.9608    0.9604       247\n",
      "weighted avg     0.9605    0.9595    0.9597       247\n",
      " samples avg     0.9595    0.9595    0.9595       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[66  2  0]\n",
      " [ 1 78  2]\n",
      " [ 0  5 93]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9221    0.9045    0.9132       157\n",
      "           1     0.8497    0.8677    0.8586       189\n",
      "           2     0.9391    0.9351    0.9371       231\n",
      "\n",
      "   micro avg     0.9047    0.9047    0.9047       577\n",
      "   macro avg     0.9036    0.9024    0.9030       577\n",
      "weighted avg     0.9052    0.9047    0.9049       577\n",
      " samples avg     0.9047    0.9047    0.9047       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[142  14   1]\n",
      " [ 12 164  13]\n",
      " [  0  15 216]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               29312     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,668\n",
      "Trainable params: 29,955\n",
      "Non-trainable params: 713\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9750    0.9630    0.9689        81\n",
      "           2     0.9798    0.9898    0.9848        98\n",
      "\n",
      "   micro avg     0.9798    0.9798    0.9798       247\n",
      "   macro avg     0.9800    0.9794    0.9797       247\n",
      "weighted avg     0.9797    0.9798    0.9797       247\n",
      " samples avg     0.9798    0.9798    0.9798       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 1 78  2]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9481    0.9299    0.9389       157\n",
      "           1     0.8947    0.8995    0.8971       189\n",
      "           2     0.9485    0.9567    0.9526       231\n",
      "\n",
      "   micro avg     0.9307    0.9307    0.9307       577\n",
      "   macro avg     0.9304    0.9287    0.9295       577\n",
      "weighted avg     0.9308    0.9307    0.9307       577\n",
      " samples avg     0.9307    0.9307    0.9307       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[146  10   1]\n",
      " [  8 170  11]\n",
      " [  0  10 221]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,196\n",
      "Trainable params: 8,611\n",
      "Non-trainable params: 585\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9577    1.0000    0.9784        68\n",
      "           1     0.9744    0.9383    0.9560        81\n",
      "           2     0.9796    0.9796    0.9796        98\n",
      "\n",
      "   micro avg     0.9717    0.9717    0.9717       247\n",
      "   macro avg     0.9706    0.9726    0.9713       247\n",
      "weighted avg     0.9719    0.9717    0.9715       247\n",
      " samples avg     0.9717    0.9717    0.9717       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 3 76  2]\n",
      " [ 0  2 96]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8848    0.9299    0.9068       157\n",
      "           1     0.8763    0.8624    0.8693       189\n",
      "           2     0.9558    0.9351    0.9453       231\n",
      "\n",
      "   micro avg     0.9099    0.9099    0.9099       577\n",
      "   macro avg     0.9056    0.9091    0.9072       577\n",
      "weighted avg     0.9104    0.9099    0.9099       577\n",
      " samples avg     0.9099    0.9099    0.9099       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[146  10   1]\n",
      " [ 17 163   9]\n",
      " [  2  13 216]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              234496    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1024)             4096      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 371,148\n",
      "Trainable params: 368,387\n",
      "Non-trainable params: 2,761\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9851    0.9706    0.9778        68\n",
      "           1     0.9750    0.9630    0.9689        81\n",
      "           2     0.9700    0.9898    0.9798        98\n",
      "\n",
      "   micro avg     0.9757    0.9757    0.9757       247\n",
      "   macro avg     0.9767    0.9744    0.9755       247\n",
      "weighted avg     0.9758    0.9757    0.9757       247\n",
      " samples avg     0.9757    0.9757    0.9757       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[66  1  1]\n",
      " [ 1 78  2]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9333    0.8917    0.9121       157\n",
      "           1     0.8663    0.8571    0.8617       189\n",
      "           2     0.9208    0.9567    0.9384       231\n",
      "\n",
      "   micro avg     0.9064    0.9064    0.9064       577\n",
      "   macro avg     0.9068    0.9019    0.9041       577\n",
      "weighted avg     0.9064    0.9064    0.9061       577\n",
      " samples avg     0.9064    0.9064    0.9064       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[140  15   2]\n",
      " [ 10 162  17]\n",
      " [  0  10 221]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               29312     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,668\n",
      "Trainable params: 29,955\n",
      "Non-trainable params: 713\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        68\n",
      "           1     1.0000    0.9877    0.9938        81\n",
      "           2     0.9899    1.0000    0.9949        98\n",
      "\n",
      "   micro avg     0.9960    0.9960    0.9960       247\n",
      "   macro avg     0.9966    0.9959    0.9962       247\n",
      "weighted avg     0.9960    0.9960    0.9959       247\n",
      " samples avg     0.9960    0.9960    0.9960       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 0 80  1]\n",
      " [ 0  0 98]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9419    0.9299    0.9359       157\n",
      "           1     0.9305    0.9206    0.9255       189\n",
      "           2     0.9617    0.9784    0.9700       231\n",
      "\n",
      "   micro avg     0.9463    0.9463    0.9463       577\n",
      "   macro avg     0.9447    0.9430    0.9438       577\n",
      "weighted avg     0.9461    0.9463    0.9461       577\n",
      " samples avg     0.9463    0.9463    0.9463       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[146   9   2]\n",
      " [  8 174   7]\n",
      " [  1   4 226]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              33792     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                32800     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,828\n",
      "Trainable params: 76,195\n",
      "Non-trainable params: 2,633\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7941    0.8852        68\n",
      "           1     0.8247    0.9877    0.8989        81\n",
      "           2     0.9792    0.9592    0.9691        98\n",
      "\n",
      "   micro avg     0.9231    0.9231    0.9231       247\n",
      "   macro avg     0.9346    0.9137    0.9177       247\n",
      "weighted avg     0.9343    0.9231    0.9230       247\n",
      " samples avg     0.9231    0.9231    0.9231       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[54 13  1]\n",
      " [ 0 80  1]\n",
      " [ 0  4 94]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.8217    0.8866       157\n",
      "           1     0.8047    0.9153    0.8564       189\n",
      "           2     0.9474    0.9351    0.9412       231\n",
      "\n",
      "   micro avg     0.8977    0.8977    0.8977       577\n",
      "   macro avg     0.9049    0.8907    0.8947       577\n",
      "weighted avg     0.9048    0.8977    0.8986       577\n",
      " samples avg     0.8977    0.8977    0.8977       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[129  27   1]\n",
      " [  5 173  11]\n",
      " [  0  15 216]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 3075      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,724\n",
      "Trainable params: 284,643\n",
      "Non-trainable params: 3,081\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.8529    0.9062        68\n",
      "           1     0.9048    0.9383    0.9212        81\n",
      "           2     0.9417    0.9898    0.9652        98\n",
      "\n",
      "   micro avg     0.9352    0.9352    0.9352       247\n",
      "   macro avg     0.9377    0.9270    0.9309       247\n",
      "weighted avg     0.9365    0.9352    0.9345       247\n",
      " samples avg     0.9352    0.9352    0.9352       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[58  7  3]\n",
      " [ 2 76  3]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9191    0.7962    0.8532       157\n",
      "           1     0.7910    0.8413    0.8154       189\n",
      "           2     0.9167    0.9524    0.9342       231\n",
      "\n",
      "   micro avg     0.8735    0.8735    0.8735       577\n",
      "   macro avg     0.8756    0.8633    0.8676       577\n",
      "weighted avg     0.8762    0.8735    0.8732       577\n",
      " samples avg     0.8735    0.8735    0.8735       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[125  31   1]\n",
      " [ 11 159  19]\n",
      " [  0  11 220]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              234496    \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 3075      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,287,628\n",
      "Trainable params: 1,287,171\n",
      "Non-trainable params: 457\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        68\n",
      "           1     1.0000    1.0000    1.0000        81\n",
      "           2     1.0000    1.0000    1.0000        98\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000       247\n",
      "   macro avg     1.0000    1.0000    1.0000       247\n",
      "weighted avg     1.0000    1.0000    1.0000       247\n",
      " samples avg     1.0000    1.0000    1.0000       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 0 81  0]\n",
      " [ 0  0 98]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9062    0.9236    0.9148       157\n",
      "           1     0.8796    0.8889    0.8842       189\n",
      "           2     0.9646    0.9437    0.9540       231\n",
      "\n",
      "   micro avg     0.9203    0.9203    0.9203       577\n",
      "   macro avg     0.9168    0.9187    0.9177       577\n",
      "weighted avg     0.9209    0.9203    0.9205       577\n",
      " samples avg     0.9203    0.9203    0.9203       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[145  11   1]\n",
      " [ 14 168   7]\n",
      " [  1  12 218]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              33792     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 3075      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,652\n",
      "Trainable params: 44,195\n",
      "Non-trainable params: 457\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9118    0.9394        68\n",
      "           1     0.8851    0.9506    0.9167        81\n",
      "           2     0.9688    0.9490    0.9588        98\n",
      "\n",
      "   micro avg     0.9393    0.9393    0.9393       247\n",
      "   macro avg     0.9409    0.9371    0.9383       247\n",
      "weighted avg     0.9413    0.9393    0.9396       247\n",
      " samples avg     0.9393    0.9393    0.9393       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[62  5  1]\n",
      " [ 2 77  2]\n",
      " [ 0  5 93]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9060    0.8599    0.8824       157\n",
      "           1     0.7788    0.8571    0.8161       189\n",
      "           2     0.9364    0.8918    0.9135       231\n",
      "\n",
      "   micro avg     0.8718    0.8718    0.8718       577\n",
      "   macro avg     0.8738    0.8696    0.8707       577\n",
      "weighted avg     0.8765    0.8718    0.8731       577\n",
      " samples avg     0.8718    0.8718    0.8718       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[135  22   0]\n",
      " [ 13 162  14]\n",
      " [  1  24 206]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                3664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,572\n",
      "Trainable params: 4,051\n",
      "Non-trainable params: 521\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9706    0.9851        68\n",
      "           1     0.9186    0.9753    0.9461        81\n",
      "           2     0.9789    0.9490    0.9637        98\n",
      "\n",
      "   micro avg     0.9636    0.9636    0.9636       247\n",
      "   macro avg     0.9659    0.9650    0.9650       247\n",
      "weighted avg     0.9650    0.9636    0.9638       247\n",
      " samples avg     0.9636    0.9636    0.9636       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[66  2  0]\n",
      " [ 0 79  2]\n",
      " [ 0  5 93]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9595    0.9045    0.9311       157\n",
      "           1     0.8593    0.9048    0.8814       189\n",
      "           2     0.9391    0.9351    0.9371       231\n",
      "\n",
      "   micro avg     0.9168    0.9168    0.9168       577\n",
      "   macro avg     0.9193    0.9148    0.9166       577\n",
      "weighted avg     0.9185    0.9168    0.9172       577\n",
      " samples avg     0.9168    0.9168    0.9168       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[142  14   1]\n",
      " [  5 171  13]\n",
      " [  1  14 216]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               29312     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,636\n",
      "Trainable params: 33,859\n",
      "Non-trainable params: 777\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9706    0.9706    0.9706        68\n",
      "           1     0.9870    0.9383    0.9620        81\n",
      "           2     0.9510    0.9898    0.9700        98\n",
      "\n",
      "   micro avg     0.9676    0.9676    0.9676       247\n",
      "   macro avg     0.9695    0.9662    0.9675       247\n",
      "weighted avg     0.9682    0.9676    0.9675       247\n",
      " samples avg     0.9676    0.9676    0.9676       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[66  0  2]\n",
      " [ 2 76  3]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9018    0.9363    0.9187       157\n",
      "           1     0.9138    0.8413    0.8760       189\n",
      "           2     0.9292    0.9654    0.9469       231\n",
      "\n",
      "   micro avg     0.9168    0.9168    0.9168       577\n",
      "   macro avg     0.9149    0.9143    0.9139       577\n",
      "weighted avg     0.9167    0.9168    0.9160       577\n",
      " samples avg     0.9168    0.9168    0.9168       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[147   9   1]\n",
      " [ 14 159  16]\n",
      " [  2   6 223]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,196\n",
      "Trainable params: 8,611\n",
      "Non-trainable params: 585\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        68\n",
      "           1     0.9639    0.9877    0.9756        81\n",
      "           2     0.9896    0.9694    0.9794        98\n",
      "\n",
      "   micro avg     0.9838    0.9838    0.9838       247\n",
      "   macro avg     0.9845    0.9857    0.9850       247\n",
      "weighted avg     0.9840    0.9838    0.9838       247\n",
      " samples avg     0.9838    0.9838    0.9838       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 0 80  1]\n",
      " [ 0  3 95]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9255    0.9490    0.9371       157\n",
      "           1     0.9000    0.9048    0.9024       189\n",
      "           2     0.9646    0.9437    0.9540       231\n",
      "\n",
      "   micro avg     0.9324    0.9324    0.9324       577\n",
      "   macro avg     0.9300    0.9325    0.9312       577\n",
      "weighted avg     0.9328    0.9324    0.9325       577\n",
      " samples avg     0.9324    0.9324    0.9324       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[149   8   0]\n",
      " [ 10 171   8]\n",
      " [  2  11 218]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,156\n",
      "Trainable params: 17,123\n",
      "Non-trainable params: 1,033\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9853    0.9926        68\n",
      "           1     0.9518    0.9753    0.9634        81\n",
      "           2     0.9794    0.9694    0.9744        98\n",
      "\n",
      "   micro avg     0.9757    0.9757    0.9757       247\n",
      "   macro avg     0.9771    0.9767    0.9768       247\n",
      "weighted avg     0.9760    0.9757    0.9758       247\n",
      " samples avg     0.9757    0.9757    0.9757       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 0 79  2]\n",
      " [ 0  3 95]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9416    0.9236    0.9325       157\n",
      "           1     0.8889    0.8889    0.8889       189\n",
      "           2     0.9359    0.9481    0.9419       231\n",
      "\n",
      "   micro avg     0.9220    0.9220    0.9220       577\n",
      "   macro avg     0.9221    0.9202    0.9211       577\n",
      "weighted avg     0.9220    0.9220    0.9220       577\n",
      " samples avg     0.9220    0.9220    0.9220       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[145  11   1]\n",
      " [  7 168  14]\n",
      " [  2  10 219]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,004\n",
      "Trainable params: 16,547\n",
      "Non-trainable params: 457\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9355    0.8529    0.8923        68\n",
      "           1     0.8621    0.9259    0.8929        81\n",
      "           2     0.9796    0.9796    0.9796        98\n",
      "\n",
      "   micro avg     0.9271    0.9271    0.9271       247\n",
      "   macro avg     0.9257    0.9195    0.9216       247\n",
      "weighted avg     0.9289    0.9271    0.9271       247\n",
      " samples avg     0.9271    0.9271    0.9271       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[58 10  0]\n",
      " [ 4 75  2]\n",
      " [ 0  2 96]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8797    0.8854    0.8825       157\n",
      "           1     0.8396    0.8307    0.8351       189\n",
      "           2     0.9397    0.9437    0.9417       231\n",
      "\n",
      "   micro avg     0.8908    0.8908    0.8908       577\n",
      "   macro avg     0.8863    0.8866    0.8864       577\n",
      "weighted avg     0.8906    0.8908    0.8907       577\n",
      " samples avg     0.8908    0.8908    0.8908       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[139  17   1]\n",
      " [ 19 157  13]\n",
      " [  0  13 218]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,012\n",
      "Trainable params: 7,491\n",
      "Non-trainable params: 521\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9710    0.9853    0.9781        68\n",
      "           1     0.9398    0.9630    0.9512        81\n",
      "           2     0.9789    0.9490    0.9637        98\n",
      "\n",
      "   micro avg     0.9636    0.9636    0.9636       247\n",
      "   macro avg     0.9632    0.9657    0.9644       247\n",
      "weighted avg     0.9639    0.9636    0.9636       247\n",
      " samples avg     0.9636    0.9636    0.9636       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 1 78  2]\n",
      " [ 1  4 93]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.9172    0.9201       157\n",
      "           1     0.8723    0.8677    0.8700       189\n",
      "           2     0.9356    0.9437    0.9397       231\n",
      "\n",
      "   micro avg     0.9116    0.9116    0.9116       577\n",
      "   macro avg     0.9103    0.9095    0.9099       577\n",
      "weighted avg     0.9115    0.9116    0.9115       577\n",
      " samples avg     0.9116    0.9116    0.9116       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[144  12   1]\n",
      " [ 11 164  14]\n",
      " [  1  12 218]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,556\n",
      "Trainable params: 8,003\n",
      "Non-trainable params: 553\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8382    0.9120        68\n",
      "           1     0.8478    0.9630    0.9017        81\n",
      "           2     0.9694    0.9694    0.9694        98\n",
      "\n",
      "   micro avg     0.9312    0.9312    0.9312       247\n",
      "   macro avg     0.9391    0.9235    0.9277       247\n",
      "weighted avg     0.9380    0.9312    0.9314       247\n",
      " samples avg     0.9312    0.9312    0.9312       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[57 11  0]\n",
      " [ 0 78  3]\n",
      " [ 0  3 95]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9448    0.8726    0.9073       157\n",
      "           1     0.8557    0.9101    0.8821       189\n",
      "           2     0.9524    0.9524    0.9524       231\n",
      "\n",
      "   micro avg     0.9168    0.9168    0.9168       577\n",
      "   macro avg     0.9176    0.9117    0.9139       577\n",
      "weighted avg     0.9187    0.9168    0.9171       577\n",
      " samples avg     0.9168    0.9168    0.9168       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[137  19   1]\n",
      " [  7 172  10]\n",
      " [  1  10 220]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               29312     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,636\n",
      "Trainable params: 33,859\n",
      "Non-trainable params: 777\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9639    0.9877    0.9756        81\n",
      "           2     0.9896    0.9694    0.9794        98\n",
      "\n",
      "   micro avg     0.9798    0.9798    0.9798       247\n",
      "   macro avg     0.9796    0.9808    0.9801       247\n",
      "weighted avg     0.9800    0.9798    0.9798       247\n",
      " samples avg     0.9798    0.9798    0.9798       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 0 80  1]\n",
      " [ 1  2 95]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9490    0.9490    0.9490       157\n",
      "           1     0.9180    0.8889    0.9032       189\n",
      "           2     0.9367    0.9610    0.9487       231\n",
      "\n",
      "   micro avg     0.9341    0.9341    0.9341       577\n",
      "   macro avg     0.9346    0.9330    0.9337       577\n",
      "weighted avg     0.9339    0.9341    0.9339       577\n",
      " samples avg     0.9341    0.9341    0.9341       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[149   7   1]\n",
      " [  7 168  14]\n",
      " [  1   8 222]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              33792     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                32800     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,828\n",
      "Trainable params: 76,195\n",
      "Non-trainable params: 2,633\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9848    0.9559    0.9701        68\n",
      "           1     0.9294    0.9753    0.9518        81\n",
      "           2     0.9896    0.9694    0.9794        98\n",
      "\n",
      "   micro avg     0.9676    0.9676    0.9676       247\n",
      "   macro avg     0.9679    0.9669    0.9671       247\n",
      "weighted avg     0.9685    0.9676    0.9678       247\n",
      " samples avg     0.9676    0.9676    0.9676       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[65  3  0]\n",
      " [ 1 79  1]\n",
      " [ 0  3 95]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9333    0.8917    0.9121       157\n",
      "           1     0.8485    0.8889    0.8682       189\n",
      "           2     0.9389    0.9307    0.9348       231\n",
      "\n",
      "   micro avg     0.9064    0.9064    0.9064       577\n",
      "   macro avg     0.9069    0.9038    0.9050       577\n",
      "weighted avg     0.9078    0.9064    0.9068       577\n",
      " samples avg     0.9064    0.9064    0.9064       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[140  15   2]\n",
      " [  9 168  12]\n",
      " [  1  15 215]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                14656     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,676\n",
      "Trainable params: 17,027\n",
      "Non-trainable params: 649\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9672    0.8676    0.9147        68\n",
      "           1     0.8370    0.9506    0.8902        81\n",
      "           2     0.9681    0.9286    0.9479        98\n",
      "\n",
      "   micro avg     0.9190    0.9190    0.9190       247\n",
      "   macro avg     0.9241    0.9156    0.9176       247\n",
      "weighted avg     0.9248    0.9190    0.9198       247\n",
      " samples avg     0.9190    0.9190    0.9190       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[59  8  1]\n",
      " [ 2 77  2]\n",
      " [ 0  7 91]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9324    0.8790    0.9049       157\n",
      "           1     0.8736    0.8413    0.8571       189\n",
      "           2     0.8988    0.9610    0.9289       231\n",
      "\n",
      "   micro avg     0.8995    0.8995    0.8995       577\n",
      "   macro avg     0.9016    0.8938    0.8970       577\n",
      "weighted avg     0.8997    0.8995    0.8989       577\n",
      " samples avg     0.8995    0.8995    0.8995       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[138  14   5]\n",
      " [ 10 159  20]\n",
      " [  0   9 222]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               16896     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,220\n",
      "Trainable params: 25,763\n",
      "Non-trainable params: 457\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9412    0.9697        68\n",
      "           1     0.9639    0.9877    0.9756        81\n",
      "           2     0.9800    1.0000    0.9899        98\n",
      "\n",
      "   micro avg     0.9798    0.9798    0.9798       247\n",
      "   macro avg     0.9813    0.9763    0.9784       247\n",
      "weighted avg     0.9802    0.9798    0.9797       247\n",
      " samples avg     0.9798    0.9798    0.9798       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[64  3  1]\n",
      " [ 0 80  1]\n",
      " [ 0  0 98]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9221    0.9045    0.9132       157\n",
      "           1     0.8608    0.8836    0.8721       189\n",
      "           2     0.9520    0.9437    0.9478       231\n",
      "\n",
      "   micro avg     0.9133    0.9133    0.9133       577\n",
      "   macro avg     0.9116    0.9106    0.9110       577\n",
      "weighted avg     0.9140    0.9133    0.9136       577\n",
      " samples avg     0.9133    0.9133    0.9133       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[142  14   1]\n",
      " [ 12 167  10]\n",
      " [  0  13 218]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,196\n",
      "Trainable params: 8,611\n",
      "Non-trainable params: 585\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9753    0.9753    0.9753        81\n",
      "           2     0.9898    0.9898    0.9898        98\n",
      "\n",
      "   micro avg     0.9838    0.9838    0.9838       247\n",
      "   macro avg     0.9835    0.9835    0.9835       247\n",
      "weighted avg     0.9838    0.9838    0.9838       247\n",
      " samples avg     0.9838    0.9838    0.9838       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 1 79  1]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.9299    0.9299       157\n",
      "           1     0.8783    0.8783    0.8783       189\n",
      "           2     0.9394    0.9394    0.9394       231\n",
      "\n",
      "   micro avg     0.9168    0.9168    0.9168       577\n",
      "   macro avg     0.9159    0.9159    0.9159       577\n",
      "weighted avg     0.9168    0.9168    0.9168       577\n",
      " samples avg     0.9168    0.9168    0.9168       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[146  10   1]\n",
      " [ 10 166  13]\n",
      " [  1  13 217]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,012\n",
      "Trainable params: 7,491\n",
      "Non-trainable params: 521\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        68\n",
      "           1     0.9873    0.9630    0.9750        81\n",
      "           2     0.9700    0.9898    0.9798        98\n",
      "\n",
      "   micro avg     0.9838    0.9838    0.9838       247\n",
      "   macro avg     0.9858    0.9843    0.9849       247\n",
      "weighted avg     0.9839    0.9838    0.9838       247\n",
      " samples avg     0.9838    0.9838    0.9838       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 0 78  3]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9241    0.9299    0.9270       157\n",
      "           1     0.8919    0.8730    0.8824       189\n",
      "           2     0.9444    0.9567    0.9505       231\n",
      "\n",
      "   micro avg     0.9220    0.9220    0.9220       577\n",
      "   macro avg     0.9201    0.9199    0.9200       577\n",
      "weighted avg     0.9217    0.9220    0.9218       577\n",
      " samples avg     0.9220    0.9220    0.9220       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[146  10   1]\n",
      " [ 12 165  12]\n",
      " [  0  10 221]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               29312     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,460\n",
      "Trainable params: 31,715\n",
      "Non-trainable params: 745\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9706    0.9851        68\n",
      "           1     0.9524    0.9877    0.9697        81\n",
      "           2     0.9897    0.9796    0.9846        98\n",
      "\n",
      "   micro avg     0.9798    0.9798    0.9798       247\n",
      "   macro avg     0.9807    0.9793    0.9798       247\n",
      "weighted avg     0.9803    0.9798    0.9798       247\n",
      " samples avg     0.9798    0.9798    0.9798       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[66  2  0]\n",
      " [ 0 80  1]\n",
      " [ 0  2 96]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9603    0.9236    0.9416       157\n",
      "           1     0.8700    0.9206    0.8946       189\n",
      "           2     0.9558    0.9351    0.9453       231\n",
      "\n",
      "   micro avg     0.9272    0.9272    0.9272       577\n",
      "   macro avg     0.9287    0.9264    0.9272       577\n",
      "weighted avg     0.9289    0.9272    0.9277       577\n",
      " samples avg     0.9272    0.9272    0.9272       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[145  11   1]\n",
      " [  6 174   9]\n",
      " [  0  15 216]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                3664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,956\n",
      "Trainable params: 4,403\n",
      "Non-trainable params: 553\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.8971    0.9242        68\n",
      "           1     0.8736    0.9383    0.9048        81\n",
      "           2     0.9792    0.9592    0.9691        98\n",
      "\n",
      "   micro avg     0.9352    0.9352    0.9352       247\n",
      "   macro avg     0.9353    0.9315    0.9327       247\n",
      "weighted avg     0.9374    0.9352    0.9356       247\n",
      " samples avg     0.9352    0.9352    0.9352       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[61  7  0]\n",
      " [ 3 76  2]\n",
      " [ 0  4 94]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8679    0.8790    0.8734       157\n",
      "           1     0.8325    0.8413    0.8368       189\n",
      "           2     0.9427    0.9264    0.9345       231\n",
      "\n",
      "   micro avg     0.8856    0.8856    0.8856       577\n",
      "   macro avg     0.8810    0.8822    0.8816       577\n",
      "weighted avg     0.8863    0.8856    0.8859       577\n",
      " samples avg     0.8856    0.8856    0.8856       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[138  17   2]\n",
      " [ 19 159  11]\n",
      " [  2  15 214]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,196\n",
      "Trainable params: 8,611\n",
      "Non-trainable params: 585\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8354    0.9706    0.8980        68\n",
      "           1     0.9571    0.8272    0.8874        81\n",
      "           2     0.9898    0.9898    0.9898        98\n",
      "\n",
      "   micro avg     0.9312    0.9312    0.9312       247\n",
      "   macro avg     0.9275    0.9292    0.9251       247\n",
      "weighted avg     0.9366    0.9312    0.9309       247\n",
      " samples avg     0.9312    0.9312    0.9312       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[66  2  0]\n",
      " [13 67  1]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7819    0.9363    0.8522       157\n",
      "           1     0.8718    0.7196    0.7884       189\n",
      "           2     0.9399    0.9481    0.9440       231\n",
      "\n",
      "   micro avg     0.8700    0.8700    0.8700       577\n",
      "   macro avg     0.8645    0.8680    0.8615       577\n",
      "weighted avg     0.8746    0.8700    0.8680       577\n",
      " samples avg     0.8700    0.8700    0.8700       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[147   9   1]\n",
      " [ 40 136  13]\n",
      " [  1  11 219]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in np.arange(0,31,1):\n",
    "    data = pd.read_csv(r\"H:\\五类数据37\\数据2\\NP-snv.csv\")\n",
    "    label = pd.read_csv(r'H:\\五类数据37\\数据2\\标签NP.csv')\n",
    "    enc = OneHotEncoder().fit_transform(label)\n",
    "    enc.toarray()\n",
    "    data.columns = np.double(data.columns)\n",
    "    label = enc.toarray()\n",
    "    x = np.array(data)\n",
    "    y = np.array(label)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.7,random_state = 300)\n",
    "    y_train = np.array(y_train)\n",
    "    clf =ak.StructuredDataClassifier(overwrite = True,loss=\"categorical_crossentropy\",metrics=\"accuracy\",max_trials=50)\n",
    "    clf.fit(x_train,y_train,epochs=300)\n",
    "    model=clf.export_model()\n",
    "    tmp = \"model_\"+str(i)+\".h5\"\n",
    "    model.save(\"tmp\")\n",
    "    loaded_model = load_model(tmp, custom_objects=ak.CUSTOM_OBJECTS)\n",
    "    loaded_model.summary()\n",
    "    y_train_predicted = loaded_model.predict(x_train)\n",
    "    y_test_predicted = loaded_model.predict(x_test)\n",
    "    for i in range(len(y_train_predicted)):\n",
    "            max_value=max(y_train_predicted[i])\n",
    "            for j in range(len(y_train_predicted[i])):\n",
    "                if max_value==y_train_predicted[i][j]:\n",
    "                    y_train_predicted[i][j]=1\n",
    "                else:\n",
    "                    y_train_predicted[i][j]=0\n",
    "    for i in range(len(y_test_predicted)):\n",
    "            max_value=max(y_test_predicted[i])\n",
    "            for j in range(len(y_test_predicted[i])):\n",
    "                if max_value==y_test_predicted[i][j]:\n",
    "                    y_test_predicted[i][j]=1\n",
    "                else:\n",
    "                    y_test_predicted[i][j]=0\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(\"\\nClassification report for classifier(train):\\n\\n%s\\n\"\n",
    "    % (metrics.classification_report(y_train, y_train_predicted,digits=4)))\n",
    "    print(\"Confusion matrix:\\n\\n%s\" % metrics.confusion_matrix(y_train.argmax(axis=1), y_train_predicted.argmax(axis=1)))\n",
    "    print(\"\\nClassification report for classifier(test):\\n\\n%s\\n\"\n",
    "    % (metrics.classification_report(y_test, y_test_predicted,digits=4)))\n",
    "    print(\"Confusion matrix:\\n\\n%s\" % metrics.confusion_matrix(y_test.argmax(axis=1), y_test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1cc89c-70ff-4b41-a4ed-32a53881acf9",
   "metadata": {},
   "source": [
    "# Select the source domain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf8e6c17-87c5-47e3-aa21-92e001035fc0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               29312     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,668\n",
      "Trainable params: 29,955\n",
      "Non-trainable params: 713\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        68\n",
      "           1     1.0000    0.9877    0.9938        81\n",
      "           2     0.9899    1.0000    0.9949        98\n",
      "\n",
      "   micro avg     0.9960    0.9960    0.9960       247\n",
      "   macro avg     0.9966    0.9959    0.9962       247\n",
      "weighted avg     0.9960    0.9960    0.9959       247\n",
      " samples avg     0.9960    0.9960    0.9960       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[68  0  0]\n",
      " [ 0 80  1]\n",
      " [ 0  0 98]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9419    0.9299    0.9359       157\n",
      "           1     0.9305    0.9206    0.9255       189\n",
      "           2     0.9617    0.9784    0.9700       231\n",
      "\n",
      "   micro avg     0.9463    0.9463    0.9463       577\n",
      "   macro avg     0.9447    0.9430    0.9438       577\n",
      "weighted avg     0.9461    0.9463    0.9461       577\n",
      " samples avg     0.9463    0.9463    0.9463       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[146   9   2]\n",
      " [  8 174   7]\n",
      " [  1   4 226]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               29312     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,636\n",
      "Trainable params: 33,859\n",
      "Non-trainable params: 777\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9853    0.9853    0.9853        68\n",
      "           1     0.9639    0.9877    0.9756        81\n",
      "           2     0.9896    0.9694    0.9794        98\n",
      "\n",
      "   micro avg     0.9798    0.9798    0.9798       247\n",
      "   macro avg     0.9796    0.9808    0.9801       247\n",
      "weighted avg     0.9800    0.9798    0.9798       247\n",
      " samples avg     0.9798    0.9798    0.9798       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 0 80  1]\n",
      " [ 1  2 95]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9490    0.9490    0.9490       157\n",
      "           1     0.9180    0.8889    0.9032       189\n",
      "           2     0.9367    0.9610    0.9487       231\n",
      "\n",
      "   micro avg     0.9341    0.9341    0.9341       577\n",
      "   macro avg     0.9346    0.9330    0.9337       577\n",
      "weighted avg     0.9339    0.9341    0.9339       577\n",
      " samples avg     0.9341    0.9341    0.9341       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[149   7   1]\n",
      " [  7 168  14]\n",
      " [  1   8 222]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              33792     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 3075      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,652\n",
      "Trainable params: 44,195\n",
      "Non-trainable params: 457\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9118    0.9394        68\n",
      "           1     0.8851    0.9506    0.9167        81\n",
      "           2     0.9688    0.9490    0.9588        98\n",
      "\n",
      "   micro avg     0.9393    0.9393    0.9393       247\n",
      "   macro avg     0.9409    0.9371    0.9383       247\n",
      "weighted avg     0.9413    0.9393    0.9396       247\n",
      " samples avg     0.9393    0.9393    0.9393       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[62  5  1]\n",
      " [ 2 77  2]\n",
      " [ 0  5 93]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9060    0.8599    0.8824       157\n",
      "           1     0.7788    0.8571    0.8161       189\n",
      "           2     0.9364    0.8918    0.9135       231\n",
      "\n",
      "   micro avg     0.8718    0.8718    0.8718       577\n",
      "   macro avg     0.8738    0.8696    0.8707       577\n",
      "weighted avg     0.8765    0.8718    0.8731       577\n",
      " samples avg     0.8718    0.8718    0.8718       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[135  22   0]\n",
      " [ 13 162  14]\n",
      " [  1  24 206]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,012\n",
      "Trainable params: 7,491\n",
      "Non-trainable params: 521\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9710    0.9853    0.9781        68\n",
      "           1     0.9398    0.9630    0.9512        81\n",
      "           2     0.9789    0.9490    0.9637        98\n",
      "\n",
      "   micro avg     0.9636    0.9636    0.9636       247\n",
      "   macro avg     0.9632    0.9657    0.9644       247\n",
      "weighted avg     0.9639    0.9636    0.9636       247\n",
      " samples avg     0.9636    0.9636    0.9636       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[67  1  0]\n",
      " [ 1 78  2]\n",
      " [ 1  4 93]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.9172    0.9201       157\n",
      "           1     0.8723    0.8677    0.8700       189\n",
      "           2     0.9356    0.9437    0.9397       231\n",
      "\n",
      "   micro avg     0.9116    0.9116    0.9116       577\n",
      "   macro avg     0.9103    0.9095    0.9099       577\n",
      "weighted avg     0.9115    0.9116    0.9115       577\n",
      " samples avg     0.9116    0.9116    0.9116       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[144  12   1]\n",
      " [ 11 164  14]\n",
      " [  1  12 218]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               16896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,396\n",
      "Trainable params: 26,851\n",
      "Non-trainable params: 1,545\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9697    0.9412    0.9552        68\n",
      "           1     0.9500    0.9383    0.9441        81\n",
      "           2     0.9604    0.9898    0.9749        98\n",
      "\n",
      "   micro avg     0.9595    0.9595    0.9595       247\n",
      "   macro avg     0.9600    0.9564    0.9581       247\n",
      "weighted avg     0.9595    0.9595    0.9594       247\n",
      " samples avg     0.9595    0.9595    0.9595       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[64  3  1]\n",
      " [ 2 76  3]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9133    0.8726    0.8925       157\n",
      "           1     0.8534    0.8624    0.8579       189\n",
      "           2     0.9322    0.9524    0.9422       231\n",
      "\n",
      "   micro avg     0.9012    0.9012    0.9012       577\n",
      "   macro avg     0.8996    0.8958    0.8975       577\n",
      "weighted avg     0.9013    0.9012    0.9011       577\n",
      " samples avg     0.9012    0.9012    0.9012       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[137  19   1]\n",
      " [ 11 163  15]\n",
      " [  2   9 220]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                14656     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,676\n",
      "Trainable params: 17,027\n",
      "Non-trainable params: 649\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9672    0.8676    0.9147        68\n",
      "           1     0.8370    0.9506    0.8902        81\n",
      "           2     0.9681    0.9286    0.9479        98\n",
      "\n",
      "   micro avg     0.9190    0.9190    0.9190       247\n",
      "   macro avg     0.9241    0.9156    0.9176       247\n",
      "weighted avg     0.9248    0.9190    0.9198       247\n",
      " samples avg     0.9190    0.9190    0.9190       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[59  8  1]\n",
      " [ 2 77  2]\n",
      " [ 0  7 91]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9324    0.8790    0.9049       157\n",
      "           1     0.8736    0.8413    0.8571       189\n",
      "           2     0.8988    0.9610    0.9289       231\n",
      "\n",
      "   micro avg     0.8995    0.8995    0.8995       577\n",
      "   macro avg     0.9016    0.8938    0.8970       577\n",
      "weighted avg     0.8997    0.8995    0.8989       577\n",
      " samples avg     0.8995    0.8995    0.8995       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[138  14   5]\n",
      " [ 10 159  20]\n",
      " [  0   9 222]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              33792     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                32800     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,828\n",
      "Trainable params: 76,195\n",
      "Non-trainable params: 2,633\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7941    0.8852        68\n",
      "           1     0.8247    0.9877    0.8989        81\n",
      "           2     0.9792    0.9592    0.9691        98\n",
      "\n",
      "   micro avg     0.9231    0.9231    0.9231       247\n",
      "   macro avg     0.9346    0.9137    0.9177       247\n",
      "weighted avg     0.9343    0.9231    0.9230       247\n",
      " samples avg     0.9231    0.9231    0.9231       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[54 13  1]\n",
      " [ 0 80  1]\n",
      " [ 0  4 94]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.8217    0.8866       157\n",
      "           1     0.8047    0.9153    0.8564       189\n",
      "           2     0.9474    0.9351    0.9412       231\n",
      "\n",
      "   micro avg     0.8977    0.8977    0.8977       577\n",
      "   macro avg     0.9049    0.8907    0.8947       577\n",
      "weighted avg     0.9048    0.8977    0.8986       577\n",
      " samples avg     0.8977    0.8977    0.8977       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[129  27   1]\n",
      " [  5 173  11]\n",
      " [  0  15 216]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,004\n",
      "Trainable params: 16,547\n",
      "Non-trainable params: 457\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9355    0.8529    0.8923        68\n",
      "           1     0.8621    0.9259    0.8929        81\n",
      "           2     0.9796    0.9796    0.9796        98\n",
      "\n",
      "   micro avg     0.9271    0.9271    0.9271       247\n",
      "   macro avg     0.9257    0.9195    0.9216       247\n",
      "weighted avg     0.9289    0.9271    0.9271       247\n",
      " samples avg     0.9271    0.9271    0.9271       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[58 10  0]\n",
      " [ 4 75  2]\n",
      " [ 0  2 96]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8797    0.8854    0.8825       157\n",
      "           1     0.8396    0.8307    0.8351       189\n",
      "           2     0.9397    0.9437    0.9417       231\n",
      "\n",
      "   micro avg     0.8908    0.8908    0.8908       577\n",
      "   macro avg     0.8863    0.8866    0.8864       577\n",
      "weighted avg     0.8906    0.8908    0.8907       577\n",
      " samples avg     0.8908    0.8908    0.8908       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[139  17   1]\n",
      " [ 19 157  13]\n",
      " [  0  13 218]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                3664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16)               64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,956\n",
      "Trainable params: 4,403\n",
      "Non-trainable params: 553\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.8971    0.9242        68\n",
      "           1     0.8736    0.9383    0.9048        81\n",
      "           2     0.9792    0.9592    0.9691        98\n",
      "\n",
      "   micro avg     0.9352    0.9352    0.9352       247\n",
      "   macro avg     0.9353    0.9315    0.9327       247\n",
      "weighted avg     0.9374    0.9352    0.9356       247\n",
      " samples avg     0.9352    0.9352    0.9352       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[61  7  0]\n",
      " [ 3 76  2]\n",
      " [ 0  4 94]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8679    0.8790    0.8734       157\n",
      "           1     0.8325    0.8413    0.8368       189\n",
      "           2     0.9427    0.9264    0.9345       231\n",
      "\n",
      "   micro avg     0.8856    0.8856    0.8856       577\n",
      "   macro avg     0.8810    0.8822    0.8816       577\n",
      "weighted avg     0.8863    0.8856    0.8859       577\n",
      " samples avg     0.8856    0.8856    0.8856       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[138  17   2]\n",
      " [ 19 159  11]\n",
      " [  2  15 214]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 3075      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,724\n",
      "Trainable params: 284,643\n",
      "Non-trainable params: 3,081\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    0.8529    0.9062        68\n",
      "           1     0.9048    0.9383    0.9212        81\n",
      "           2     0.9417    0.9898    0.9652        98\n",
      "\n",
      "   micro avg     0.9352    0.9352    0.9352       247\n",
      "   macro avg     0.9377    0.9270    0.9309       247\n",
      "weighted avg     0.9365    0.9352    0.9345       247\n",
      " samples avg     0.9352    0.9352    0.9352       247\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[58  7  3]\n",
      " [ 2 76  3]\n",
      " [ 0  1 97]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9191    0.7962    0.8532       157\n",
      "           1     0.7910    0.8413    0.8154       189\n",
      "           2     0.9167    0.9524    0.9342       231\n",
      "\n",
      "   micro avg     0.8735    0.8735    0.8735       577\n",
      "   macro avg     0.8756    0.8633    0.8676       577\n",
      "weighted avg     0.8762    0.8735    0.8732       577\n",
      " samples avg     0.8735    0.8735    0.8735       577\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[125  31   1]\n",
      " [ 11 159  19]\n",
      " [  0  11 220]]\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1,11,1):\n",
    "    data = pd.read_csv(r\"H:\\五类数据37\\数据2\\NP-snv.csv\")\n",
    "    label = pd.read_csv(r'H:\\五类数据37\\数据2\\标签NP.csv')\n",
    "    enc = OneHotEncoder().fit_transform(label)\n",
    "    enc.toarray()\n",
    "    data.columns = np.double(data.columns)\n",
    "    label = enc.toarray()\n",
    "    x = np.array(data)\n",
    "    y = np.array(label)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.7,random_state = 300)\n",
    "    y_train = np.array(y_train)\n",
    "    tmp = \"model_\"+str(i)+\".h5\"\n",
    "    loaded_model = load_model(tmp, custom_objects=ak.CUSTOM_OBJECTS)\n",
    "    loaded_model.summary()\n",
    "    y_train_predicted = loaded_model.predict(x_train)\n",
    "    y_test_predicted = loaded_model.predict(x_test)\n",
    "    for i in range(len(y_train_predicted)):\n",
    "            max_value=max(y_train_predicted[i])\n",
    "            for j in range(len(y_train_predicted[i])):\n",
    "                if max_value==y_train_predicted[i][j]:\n",
    "                    y_train_predicted[i][j]=1\n",
    "                else:\n",
    "                    y_train_predicted[i][j]=0\n",
    "    for i in range(len(y_test_predicted)):\n",
    "            max_value=max(y_test_predicted[i])\n",
    "            for j in range(len(y_test_predicted[i])):\n",
    "                if max_value==y_test_predicted[i][j]:\n",
    "                    y_test_predicted[i][j]=1\n",
    "                else:\n",
    "                    y_test_predicted[i][j]=0\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(\"\\nClassification report for classifier(train):\\n\\n%s\\n\"\n",
    "    % (metrics.classification_report(y_train, y_train_predicted,digits=4)))\n",
    "    print(\"Confusion matrix:\\n\\n%s\" % metrics.confusion_matrix(y_train.argmax(axis=1), y_train_predicted.argmax(axis=1)))\n",
    "    print(\"\\nClassification report for classifier(test):\\n\\n%s\\n\"\n",
    "    % (metrics.classification_report(y_test, y_test_predicted,digits=4)))\n",
    "    print(\"Confusion matrix:\\n\\n%s\" % metrics.confusion_matrix(y_test.argmax(axis=1), y_test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f7360-3614-4bbf-9930-750945399d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac073da-e24b-4226-bcde-7cda9a9f90e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea203ae9-abd5-413c-a673-403bff4b172d",
   "metadata": {},
   "source": [
    "# transfer 3:7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90107ee-2a84-43bf-9bec-bb601763fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import target domain data\n",
    "x_target_sets = pd.read_csv(r\".\\FM-snv.csv\")\n",
    "y_target_sets = pd.read_csv(r\".\\label_FM.csv\")\n",
    "enc2 = OneHotEncoder().fit_transform(y_target_sets)\n",
    "enc2.toarray()\n",
    "x_target_sets.columns = np.double(x_target_sets.columns)\n",
    "y_target_sets = enc2.toarray()\n",
    "x_target_sets = np.array(x_target_sets)\n",
    "x_t_train, x_t_test,y_t_train,y_t_test = train_test_split(x_target_sets,y_target_sets,test_size = 0.7,random_state = 300) \n",
    "y_t_train = np.array(y_t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df297a53-5a99-4c7a-ab93-d5504d56963e",
   "metadata": {},
   "source": [
    "# Import the source domain model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62caf4e1-9b13-4316-bd86-68e5d8d6cb44",
   "metadata": {},
   "source": [
    "# Take layers from a previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f176ebd-68f8-4624-879c-35059e66187e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228)]             0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 3)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,012\n",
      "Trainable params: 7,491\n",
      "Non-trainable params: 521\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target_sets = pd.read_csv(r\".\\FM-snv.csv\")        \n",
    "y_target_sets = pd.read_csv(r\".\\label_FM.csv\")\n",
    "enc2 = OneHotEncoder().fit_transform(y_target_sets)\n",
    "enc2.toarray()\n",
    "x_target_sets.columns = np.double(x_target_sets.columns)\n",
    "y_target_sets = enc2.toarray()                                           # Hot coding alone\n",
    "x_target_sets = np.array(x_target_sets)\n",
    "x_t_train, x_t_test,y_t_train,y_t_test = train_test_split(x_target_sets,y_target_sets,test_size = 0.7,random_state = 300)    #Divide training set and test set\n",
    "y_t_train = np.array(y_t_train)\n",
    "loaded_model = load_model(\"./model_4.h5\", custom_objects=ak.CUSTOM_OBJECTS)       # Import the model\n",
    "loaded_model.summary()\n",
    "len(loaded_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfbe7bb3-1522-41dc-a1fd-658011ddbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd3c2ec6-835d-4d89-a51c-bd964a6e971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = tf.keras.Sequential()        #Take layers from a previously trained model\n",
    "model_new.add(loaded_model.layers[-9])\n",
    "model_new.add(loaded_model.layers[-8])\n",
    "model_new.add(loaded_model.layers[-7])\n",
    "model_new.add(loaded_model.layers[-6])\n",
    "model_new.add(loaded_model.layers[-5])\n",
    "model_new.add(loaded_model.layers[-4])\n",
    "model_new.add(loaded_model.layers[-3])\n",
    "# model_new.add(loaded_model.layers[-2])\n",
    "model_new.add(Dense(3,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58060f95-c845-4bcb-9fdf-7164840190be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8759\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8828\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8897\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8897\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8276\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8828\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8828\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8759\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8897\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8828\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9034\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.9034\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.9034\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8897\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8828\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8621\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8552\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8897\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8621\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.9034\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8483\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8759\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.9034\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8759\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.9034\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8759\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.9034\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8897\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8828\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.9103\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.9034\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.9034\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8621\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8897\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8621\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8690\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.9103\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8483\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.9034\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.9034\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9379\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8621\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.9172\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.9103\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8897\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8483\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.9034\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8759\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.9310\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.9103\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9034\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8828\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.9241\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8345\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8621\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8759\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.9034\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2414 - accuracy: 0.9517\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8966\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.9103\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8690\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8966\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9034\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.9103\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.9379\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8690\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8966\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.9103\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.9310\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8897\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8759\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.9103\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8966\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.8828\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8759\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9172\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8759\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.9172\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.9241\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9103\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8483\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8828\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9103\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8828\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9241\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.8897\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9103\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.9034\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.9103\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8759\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.9034\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9103\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9034\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8759\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9034\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8759\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8828\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9103\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8828\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.9310\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8828\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.9034\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9034\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.9034\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8966\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8897\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8966\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.9172\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.9172\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8759\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8759\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.9034\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.9034\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8621\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9379\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.9034\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8897\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8759\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.9034\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8897\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.9034\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9172\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9172\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.9241\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8828\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8897\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.9034\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8897\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9034\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8552\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8759\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9103\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8966\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8759\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8897\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8897\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.9172\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.9241\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9241\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9034\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8966\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9034\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.9172\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8828\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.8966\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8966\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9172\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.9172\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.9103\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8966\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9034\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9241\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.9379\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8828\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9103\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8828\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8759\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.9034\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.8897\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8966\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8966\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.9103\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8828\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8966\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.9172\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8966\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.9172\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9241\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8828\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9172\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9103\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8828\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9241\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9172\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8759\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8828\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9103\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8897\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8828\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.9103\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9103\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8966\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8897\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.9172\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9034\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.9172\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9310\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9103\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8966\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9379\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9034\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.9103\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.9172\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8966\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.8828\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9103\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.9034\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9172\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8759\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9310\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9241\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.9241\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.9034\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8552\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9379\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.8897\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8897\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9034\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8828\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8897\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8966\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9034\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.9103\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8897\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.8966\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8828\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8690\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8966\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8966\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.9103\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9241\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8897\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9241\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.9103\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9310\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9103\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9379\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8828\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9103\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9103\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.9034\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9034\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9241\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.8966\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8897\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9103\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9310\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9241\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.9172\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9172\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.9034\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9103\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8828\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8828\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8759\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9241\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9034\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8759\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8828\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8690\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8759\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.9034\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9172\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8897\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9310\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8966\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9103\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9310\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.9034\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9103\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.9241\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8897\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.9034\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9379\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8828\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8828\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9103\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9172\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8897\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.9034\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9172\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9103\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8828\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8828\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8690\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8897\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8966\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.9172\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9241\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8759\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8828\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8966\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9379\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9103\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.9172\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9241\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.9172\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8897\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8966\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8966\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9379\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8759\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.9034\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.9034\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.9310\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9034\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8966\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9103\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9310\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9310\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.9172\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.9172\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9103\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9103\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8828\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9517\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9034\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8966\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.9172\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8897\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9034\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9241\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9103\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8759\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9379\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9103\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9103\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9172\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9310\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8759\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8966\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8828\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9448\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.9103\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9379\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9034\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.9172\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9241\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9103\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9241\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8897\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9310\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9448\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8966\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9379\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9172\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.9034\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9241\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9034\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.9241\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9310\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.9241\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9103\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.9034\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9103\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8966\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9310\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8828\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9448\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8759\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9172\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9241\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9310\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.9103\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8897\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.9241\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8966\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.8897\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9103\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.8897\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9241\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9241\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9034\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8759\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8897\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9034\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9103\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9103\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9310\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9448\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9034\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.9034\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9241\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8966\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9310\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9379\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9172\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9103\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9034\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.9034\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9310\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.8897\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8966\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9379\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.8828\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9172\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8897\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8828\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8759\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8966\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9310\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9379\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9034\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9103\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.8966\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8897\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9172\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9379\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9172\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.9034\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9310\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.9034\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9103\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.9103\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8966\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9103\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9310\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8897\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.9103\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.8966\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9310\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8966\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9034\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9241\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9310\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9310\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9310\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9103\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9172\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8897\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9172\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.9241\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.8897\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9172\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.9103\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9379\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.8966\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.9034\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8966\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9172\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9103\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.9103\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9310\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8966\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9103\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9310\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9241\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9034\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9310\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9172\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9310\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9448\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9034\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9241\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9241\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9103\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9103\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9379\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9448\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9103\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.9241\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9103\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9172\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.8828\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9034\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9379\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9241\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8897\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9103\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8966\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8897\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9241\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9241\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8828\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9172\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8828\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2198 - accuracy: 0.9241\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8966\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9103\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9310\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9379\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.9172\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9379\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9241\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8966\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9379\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8966\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.9103\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9310\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.8966\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9034\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.8897\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.9172\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8828\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.9172\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8897\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9379\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9103\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9172\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9241\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9310\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9034\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9379\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9241\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9034\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9379\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9241\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9379\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9241\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.9034\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.2998 - accuracy: 0.8912\n",
      "[0.2998489737510681, 0.8911764621734619]\n"
     ]
    }
   ],
   "source": [
    "model_new.trainable = True                                    # Freezing layers\n",
    "model_new.layers[-7].trainable = False\n",
    "model_new.layers[-6].trainable = False\n",
    "model_new.layers[-5].trainable = True\n",
    "model_new.layers[-4].trainable = False\n",
    "model_new.layers[-3].trainable = True\n",
    "model_new.layers[-2].trainable = True\n",
    "model_new.layers[-1].trainable = True\n",
    "model_new.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001),     #compile new model\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "for i in np.arange(1,2,1):\n",
    "    history = model_new.fit(x_t_train,y_t_train,epochs=500)    #Training new model \n",
    "inputs = tf.keras.Input(shape=(228,))\n",
    "model = tf.keras.Model(inputs)\n",
    "predicted_t_y = model_new.predict(x_t_test)    #  Use the new model to make predictions\n",
    "model_new.save(r\"H:\\五类数据37\\tran_model\\model_new_autokeras4-2.h5\")    # save new model\n",
    "print(model_new.evaluate(x_t_test, y_t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2126f0fd-8ce5-489f-bcb4-5dc7b207ae52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6fac2-bee7-47ef-a865-31b77c488929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4261e-f5c6-4345-86e3-bfb6b2da9f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe786a3-ef73-4ce4-8e97-0e052dcce376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b9c2d-4e1b-4cd8-ac28-78df0cb9dc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eee08dd-53bf-4a72-9eef-b9b8b8144152",
   "metadata": {},
   "source": [
    "# Viewing model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf095cdd-501b-4adf-96c7-5fdc1d17b29a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " multi_category_encoding (Mu  (None, 228)              0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 228)              457       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                7328      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32)               128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,012\n",
      "Trainable params: 7,427\n",
      "Non-trainable params: 585\n",
      "_________________________________________________________________\n",
      "\n",
      "Classification report for classifier(train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9859    1.0000    0.9929        70\n",
      "           1     0.9615    0.9091    0.9346        55\n",
      "           2     0.8182    0.9000    0.8571        20\n",
      "\n",
      "   micro avg     0.9517    0.9517    0.9517       145\n",
      "   macro avg     0.9219    0.9364    0.9282       145\n",
      "weighted avg     0.9535    0.9517    0.9521       145\n",
      " samples avg     0.9517    0.9517    0.9517       145\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[70  0  0]\n",
      " [ 1 50  4]\n",
      " [ 0  2 18]]\n",
      "\n",
      "Classification report for classifier(test):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9226    0.9226    0.9226       155\n",
      "           1     0.9016    0.8943    0.8980       123\n",
      "           2     0.7937    0.8065    0.8000        62\n",
      "\n",
      "   micro avg     0.8912    0.8912    0.8912       340\n",
      "   macro avg     0.8726    0.8744    0.8735       340\n",
      "weighted avg     0.8915    0.8912    0.8913       340\n",
      " samples avg     0.8912    0.8912    0.8912       340\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[143   6   6]\n",
      " [  6 110   7]\n",
      " [  6   6  50]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(r\"H:\\五类数据37\\tran_model\\model_new_autokeras4-2.h5\", custom_objects=ak.CUSTOM_OBJECTS)\n",
    "loaded_model.summary()\n",
    "y_train_predicted = loaded_model.predict(x_t_train)\n",
    "y_test_predicted = loaded_model.predict(x_t_test)\n",
    "for i in range(len(y_train_predicted)):\n",
    "        max_value=max(y_train_predicted[i])\n",
    "        for j in range(len(y_train_predicted[i])):\n",
    "            if max_value==y_train_predicted[i][j]:\n",
    "                y_train_predicted[i][j]=1\n",
    "            else:\n",
    "                y_train_predicted[i][j]=0\n",
    "for i in range(len(y_test_predicted)):\n",
    "        max_value=max(y_test_predicted[i])\n",
    "        for j in range(len(y_test_predicted[i])):\n",
    "            if max_value==y_test_predicted[i][j]:\n",
    "                y_test_predicted[i][j]=1\n",
    "            else:\n",
    "                y_test_predicted[i][j]=0\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nClassification report for classifier(train):\\n\\n%s\\n\"\n",
    "% (metrics.classification_report(y_t_train, y_train_predicted,digits=4)))\n",
    "print(\"Confusion matrix:\\n\\n%s\" % metrics.confusion_matrix(y_t_train.argmax(axis=1), y_train_predicted.argmax(axis=1)))\n",
    "print(\"\\nClassification report for classifier(test):\\n\\n%s\\n\"\n",
    "% (metrics.classification_report(y_t_test, y_test_predicted,digits=4)))\n",
    "print(\"Confusion matrix:\\n\\n%s\" % metrics.confusion_matrix(y_t_test.argmax(axis=1), y_test_predicted.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d2f7a-c90e-40db-9b82-9d98cc2aa0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9e587-cb4d-407f-b974-db739ac3d682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51442e4b-c7ae-4397-b663-7cfc10c31fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336e528-7e86-43b2-8537-d40a73fde979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc1edc-3487-469d-bbcf-1e233a7c3541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd9fa7-7ad1-4b1c-aea5-fab6da3ffd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f674775-2c94-4669-add8-526e15e7759d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
